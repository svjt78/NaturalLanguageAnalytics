


```markdown
# ğŸ§  Natural Language Analytics

A full-stack, containerized system that lets users upload raw tabular data (CSV/XLSX), auto-generate semantic metadata and metrics, and query the data using natural language (NL). Powered by LLMs, LangChain, Streamlit, and FastAPI.

## ğŸš€ Features

- ğŸ“¥ Upload CSV or Excel files for ingestion
- ğŸ” Automatic extraction of column metadata (type, name, etc.)
- ğŸ§  GPT-powered column dictionary creation
- ğŸ“Š Auto-generated metrics based on heuristics (SUM, AVG, counts, etc.)
- ğŸ’¬ Ask natural language questions â†’ get SQL + answers
- ğŸ“ˆ Streamlit frontend with visualizations and step tracking
- ğŸ”„ Hot-reloading dev environment with Docker Compose

---

## ğŸ“¦ Architecture

```

```
         â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
         â”‚  Streamlit   â”‚ â—„â”€â”€â”€â”€â”€â”€ User uploads, queries
         â””â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
        REST API Calls
               â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”€â”€â”
      â”‚    FastAPI      â”‚ â—„â”€â”€â”€â”€â”€ `/ingest`, `/metrics`, `/query`
      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
     LangGraph Pipeline
               â”‚
```

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        â”‚                 â”‚        â”‚
â–¼        â–¼                 â–¼        â–¼
Extractor  â†’  Dictionary Agent  â†’  Analyst Agent
(sqlalchemy)   (OpenAI GPT-4o)   (heuristics â†’ metrics)

```

---

## ğŸ“‚ Project Structure

```

.
â”œâ”€â”€ backend
â”‚   â”œâ”€â”€ agents/             # Core agent logic (extractor, GPT dictionary, metrics)
â”‚   â”œâ”€â”€ db.py               # Async SQLAlchemy DB session
â”‚   â”œâ”€â”€ models.py           # ORM Models: ColumnMeta, Dictionary, Metrics, etc.
â”‚   â”œâ”€â”€ graph.py            # LangGraph pipeline setup
â”‚   â”œâ”€â”€ ingestor.py         # File ingestion logic (create/replace/append)
â”‚   â”œâ”€â”€ main.py             # FastAPI server
â”‚   â”œâ”€â”€ create\_tables.py    # Manual DB init script
â”‚   â”œâ”€â”€ migrations/         # Alembic migration scripts
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ frontend
â”‚   â”œâ”€â”€ app.py              # Streamlit frontend
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ docker-compose.yml      # Dev environment with Postgres, Backend, Frontend
â””â”€â”€ .env                    # Secrets and DB config

````

---

## ğŸ› ï¸ Tech Stack

| Layer     | Tech                     |
|-----------|--------------------------|
| Backend   | Python, FastAPI, SQLAlchemy, LangChain, Alembic |
| Frontend  | Streamlit + Plotly       |
| LLMs      | OpenAI GPT-4o (via API)  |
| DB        | PostgreSQL               |
| DevOps    | Docker, Docker Compose   |

---

## ğŸ“Œ Setup Instructions

1. **Clone the Repo**

```bash
git clone https://github.com/your-username/natural-language-analytics.git
cd natural-language-analytics
````

2. **Set Environment Variables**

Create a `.env` file in the root of the project with the following:

```env
OPENAI_API_KEY=sk-...
DATABASE_URL=postgresql+asyncpg://postgres:postgres@db:5432/analytics_db
API_BASE=http://backend:8000
```

3. **Run with Docker Compose**

```bash
docker-compose up --build
```

* Streamlit UI: [http://localhost:8501](http://localhost:8501)
* FastAPI backend: [http://localhost:8000/docs](http://localhost:8000/docs)
* PostgreSQL: localhost:5432

---

## ğŸ§ª Example Flow

1. **Upload** a CSV or Excel file (Tab 1).
2. **Watch** as the system:

   * Extracts schema & types
   * Generates descriptions (GPT)
   * Computes metrics (sum, avg, counts)
3. **Explore** metrics (Tab 2).
4. **Ask** questions in plain English (Tab 3):

   * *"What is the average order amount per customer?"*
   * *"Show top 10 countries by transaction count"*

---

## ğŸ“ˆ Sample Metric JSON Output

```json
{
  "metric_name": "orders.amount_avg",
  "sql_definition": "SELECT AVG(\"amount\") AS \"avg_amount\" FROM \"orders\"",
  "viz_hint": {
    "x": null,
    "y": "avg_amount",
    "type": "numeric"
  },
  "tags": ["orders", "amount", "avg"]
}
```

---

## ğŸ§ª Developer Tips

* You can trigger ingestion directly with: `curl -F 'file=@file.csv' http://localhost:8000/ingest/`
* Use `create_tables.py` to bootstrap your DB schema
* Modify `query_runner.py` if you want to switch LLM providers or prompts

---

## ğŸ§¾ License

MIT License Â© 2025 \[Your Name]

---

## ğŸ™Œ Acknowledgements

* [LangChain](https://www.langchain.com/)
* [OpenAI](https://openai.com/)
* [Streamlit](https://streamlit.io/)
* [SQLAlchemy](https://www.sqlalchemy.org/)

